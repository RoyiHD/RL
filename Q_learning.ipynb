{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q Learning Awesome Mouse-Maze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"resources/images/screen_shot.png\" alt=\"Mouse Maze\" width=\"300\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<label>Implementation of the Q learning module</label>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 1: Create AI Module</h3>\n",
    "<li>Create new ai.py file</li>\n",
    "<li>Create class AI()</li>\n",
    "<li>Init variables</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AI:\n",
    "\n",
    "    def __init__(self, Q, epsilon=0.15, alpha=0.05, discount=0.99):\n",
    "        \n",
    "        #Radom action probability rate\n",
    "        self.epsilon = epsilon\n",
    "        #Learning rate\n",
    "        self.alpha = alpha\n",
    "        #Rate which determines how much weight is given to future rewards\n",
    "        self.discount = discount\n",
    "        self.START_E = epsilon\n",
    "        self.END_E = 0.05\n",
    "        #Possible game actions\n",
    "        self.actions = [\"LEFT\", \"RIGHT\", \"UP\", \"DOWN\"]\n",
    "        #Our Q table \n",
    "        self.Q = Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 2: Choose Action </h3>\n",
    "<li>Compare random vs epsilon</li>\n",
    "<li>Find the action with the maximum q value</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_action(self, state, epsilon):\n",
    "\n",
    "    if random() < epsilon:\n",
    "        return choice(self.actions)\n",
    "\n",
    "    actions = [self.Q.get((state+\"-\"+i), 0.0) for i in self.actions]\n",
    "    _max = max(actions)\n",
    "\n",
    "    if actions.count(_max) > 0:\n",
    "        index =  choice([i for i in range(len(self.actions)) if actions[i] == _max])\n",
    "    else:\n",
    "        index = actions.index(_max)\n",
    "\n",
    "    return self.actions[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 3: Learn Function </h3>\n",
    "<li>Get Max value for new state across all actions</li>\n",
    "<li>Apply Bellman equation to update previous state Q value</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(self, reward, state, action, prev_state):\n",
    "\n",
    "    _max_val = max([self.Q.get((\"%s-%s\"% (state, i)), 0.0)for i in self.actions])\n",
    "    _val = self.Q.get((\"%s-%s\" % (prev_state, action)), 0.0)\n",
    "    new_val = _val + self.alpha * (reward + (self.discount * _max_val) - _val)\n",
    "    self.Q[(\"%s-%s\" % (prev_state, action))] = new_val\n",
    "\n",
    "    return new_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Helper function</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_total_rewards(self):\n",
    "    return sum([val for val in self.Q.values()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Rewards(Top) & Exploration vs Exploitation(Bottom) </h2>\n",
    "<img src=\"resources/images/data_screen_shot.png\" width=\"500\" height=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Trained game board</h2>\n",
    "<img src=\"resources/images/train_screen_shot.png\" width=\"500\" height=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Complete AI class</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import  random, choice\n",
    "\n",
    "class AI:\n",
    "\n",
    "    def __init__(self, Q, epsilon=0.15, alpha=0.05, discount=0.99):\n",
    "\n",
    "        self.epsilon = epsilon\n",
    "        self.alpha = alpha\n",
    "        self.discount = discount\n",
    "        self.START_E = epsilon\n",
    "        self.END_E = 0.05\n",
    "        self.actions = [\"LEFT\", \"RIGHT\", \"UP\", \"DOWN\"]\n",
    "        self.Q = Q\n",
    "\n",
    "\n",
    "    def learn(self, reward, state, action, prev_state):\n",
    "\n",
    "        _max_val = max([self.Q.get((\"%s-%s\"% (state, i)), 0.0)for i in self.actions])\n",
    "        _val = self.Q.get((\"%s-%s\" % (prev_state, action)), 0.0)\n",
    "        new_val = _val + self.alpha * (reward + (self.discount * _max_val) - _val)\n",
    "        self.Q[(\"%s-%s\" % (prev_state, action))] = new_val\n",
    "\n",
    "        return new_val\n",
    "\n",
    "    def choose_action(self, state, epsilon):\n",
    "\n",
    "        if random() < epsilon:\n",
    "            return choice(self.actions)\n",
    "\n",
    "        actions = [self.Q.get((\"%s-%s\" % (state,i)), 0.0) for i in self.actions]\n",
    "        _max = max(actions)\n",
    "\n",
    "        if actions.count(_max) > 0:\n",
    "            index =  choice([i for i in range(len(self.actions)) if actions[i] == _max])\n",
    "        else:\n",
    "            index = actions.index(_max)\n",
    "\n",
    "        return self.actions[index]\n",
    "\n",
    "    def calculate_total_rewards(self):\n",
    "        return sum([val for val in self.Q.values()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Complete code for main.py</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from env import MouseMaze\n",
    "from ai import AI\n",
    "import utils\n",
    "import time\n",
    "\n",
    "START_e = 0.99\n",
    "END_e = 0.0005\n",
    "\n",
    "def run(env, ai, train):\n",
    "\n",
    "    state = env.get_state()\n",
    "    epsilon = START_e if len(ai.Q) <= 0 else END_e\n",
    "    if not train:\n",
    "        epsilon = -1\n",
    "\n",
    "    iter = 0\n",
    "    rewards = []\n",
    "    epsilons = []\n",
    "    while \"luke\" != \"last_jedi\":\n",
    "        \n",
    "        action = ai.choose_action(state, epsilon)\n",
    "        new_state, reward, status = env.get_frame_step(action)\n",
    "\n",
    "        if epsilon > END_e:\n",
    "            epsilon -= END_e\n",
    "\n",
    "        #calculating new q value based on new state\n",
    "        q_val = ai.learn(reward, new_state, action, state)\n",
    "\n",
    "        #Updating text to show values\n",
    "        env.update(q_val, state, new_state)\n",
    "\n",
    "\n",
    "        if iter % 50 == 0:\n",
    "            utils.save_j(ai.Q, 'resources/q.json')\n",
    "            utils.save_j(env.values, 'resources/values.json')\n",
    "            sum_rewards = ai.calculate_total_rewards()\n",
    "            rewards.append(sum_rewards)\n",
    "            epsilons.append(epsilon)\n",
    "            utils.save_j({'rewards':rewards, 'epsilon':epsilons}, 'resources/data.json')\n",
    "            print(\"Iter %d Accumulated Rewards %f with Epsilon %f\" % (iter, sum_rewards , epsilon))\n",
    "\n",
    "        state = new_state\n",
    "        iter += 1\n",
    "        if status:\n",
    "            state = env.reset()\n",
    "\n",
    "        if not train:\n",
    "            time.sleep(0.1)\n",
    "\n",
    "\n",
    "def plot_stuff():\n",
    "    data = utils.load_j('resources/data.json')\n",
    "    rewards, epsilon = data['rewards'], data['epsilon']\n",
    "\n",
    "    #print(rewards)\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(rewards)\n",
    "    plt.ylabel('rewards')\n",
    "    plt.xlabel('iterations (hundreds)')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(epsilon)\n",
    "    plt.ylabel('epsilon')\n",
    "    plt.xlabel('iterations (hundreds)')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    #plot_stuff()\n",
    "    ai = AI(utils.load_j('resources/q.json'))\n",
    "    game = MouseMaze(utils.load_j('resources/values.json'))\n",
    "    run(game, ai, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}